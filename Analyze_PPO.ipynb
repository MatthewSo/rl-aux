{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d8f36f-080f-4f1b-ad09-942b862aedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cml0/rl-aux2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc49b92-fd8d-48e1-857b-75a9caf9f86c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mT\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CIFAR100\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcifar100\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CIFAR100, CoarseLabelCIFAR100\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cifar_trans_train, cifar_trans_test\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvironment\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlearn_weight_aux_task\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AuxTaskEnv\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from tabnanny import verbose\n",
    "\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR100\n",
    "from datasets.cifar100 import CIFAR100, CoarseLabelCIFAR100\n",
    "from datasets.transforms import cifar_trans_train, cifar_trans_test\n",
    "from environment.learn_weight_aux_task import AuxTaskEnv\n",
    "from environment.weight_training.weight_training_environment import WeightTuningEnv\n",
    "from networks.ppo.ppo import get_ppo_agent\n",
    "from networks.primary.vgg import VGG16\n",
    "from networks.weight_training.ppo import get_weight_training_ppo_agent\n",
    "from train.train_auxilary_agent import train_auxilary_agent\n",
    "from utils.analysis.network_details import print_aux_weights\n",
    "from utils.log import log_print, change_log_location\n",
    "from utils.path_name import create_path_name, save_all_parameters\n",
    "\n",
    "LOAD_MODEL_PATH = \"/home/cml0/rl-aux/trained_models/PPO_VGG_learn_weights_False_train_ratio_1_aux_weight_1_obs_dim_256_CIFAR100-20v2/best_model_auxiliary\"\n",
    "BATCH_SIZE = 100\n",
    "AUX_DIMENSION = 100\n",
    "PRIMARY_DIMENSION = 20\n",
    "OBSERVATION_FEATURE_DIMENSION = 256\n",
    "TOTAL_EPOCH = 200\n",
    "PRIMARY_LEARNING_RATE = 0.01\n",
    "PPO_LEARNING_RATE = 1e-4\n",
    "SCHEDULER_STEP_SIZE = 50\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "AUX_WEIGHT = 0\n",
    "LEARN_WEIGHTS = True\n",
    "TRAIN_RATIO = 1\n",
    "\n",
    "SAVE_PATH=\"./\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cifar100_train_set = CIFAR100(root='dataset', train=True, transform=cifar_trans_test, download=True)\n",
    "cifar100_test_set = CIFAR100(root='dataset', train=False, transform=cifar_trans_test, download=True)\n",
    "\n",
    "course_cifar_train_set = CoarseLabelCIFAR100(cifar100_train_set)\n",
    "course_cifar_test_set = CoarseLabelCIFAR100(cifar100_test_set)\n",
    "\n",
    "cifar100_train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=course_cifar_train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "cifar100_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=course_cifar_test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "primary_model = VGG16(\n",
    "    primary_task_output=PRIMARY_DIMENSION,\n",
    "    auxiliary_task_output=AUX_DIMENSION\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_callback = lambda x: torch.optim.SGD(x.parameters(), lr=PRIMARY_LEARNING_RATE)\n",
    "scheduler_callback = lambda x: torch.optim.lr_scheduler.StepLR(x, step_size=SCHEDULER_STEP_SIZE, gamma=SCHEDULER_GAMMA)\n",
    "# ---------\n",
    "\n",
    "task_env = AuxTaskEnv(\n",
    "    train_dataset=course_cifar_train_set,\n",
    "    device=device,\n",
    "    model=primary_model,\n",
    "    criterion=criterion,\n",
    "    optimizer_func=optimizer_callback,\n",
    "    scheduler_func=scheduler_callback,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pri_dim=PRIMARY_DIMENSION,\n",
    "    aux_dim=AUX_DIMENSION,\n",
    "    aux_weight=AUX_WEIGHT,\n",
    "    save_path=SAVE_PATH,\n",
    "    learn_weights=LEARN_WEIGHTS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "auxilary_task_agent = get_ppo_agent(env=task_env,\n",
    "                                    feature_dim=OBSERVATION_FEATURE_DIMENSION,\n",
    "                                    auxiliary_dim=AUX_DIMENSION,\n",
    "                                    learning_rate=PPO_LEARNING_RATE,\n",
    "                                    device=device,\n",
    "                                    ent_coef=0.01,\n",
    "                                    n_steps=79,\n",
    "                                    n_epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    weight_bins=21,\n",
    "                                    )\n",
    "\n",
    "auxilary_task_agent.set_parameters(LOAD_MODEL_PATH, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019e688-de32-4a7a-b4cf-a86eca7b4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cifar100_train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300d0ac-a64f-47b8-b8c1-e2e41918dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_image(i):\n",
    "    img_norm, label_idx = cifar100_test_set[32]\n",
    "    mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)\n",
    "    std  = torch.tensor([0.2, 0.2, 0.2]).view(3, 1, 1)\n",
    "    img = (img_norm * std) + mean\n",
    "    img = img.clamp(0, 1)                        \n",
    "    \n",
    "    plt.imshow(img.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce1dc5-9698-4ffd-831e-4dd4e3ca754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    img_norm, label_idx = cifar100_test_set[i]\n",
    "    obs = {\"image\":img_norm}\n",
    "    #print(i)\n",
    "    print(auxilary_task_agent.predict(obs, deterministic=True)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e28167-a484-4e83-883e-1c5a1b778ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160f952-efa5-4106-9852-3319f460695c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
